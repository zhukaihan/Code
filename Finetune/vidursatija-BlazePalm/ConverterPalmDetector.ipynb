{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConverterPalmDetector.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uunDZm8ryFU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a455edd1-8754-4d10-a86b-62a34bde040c"
      },
      "source": [
        "!git clone https://github.com/google/flatbuffers.git\n",
        "!cd flatbuffers && cmake -G \"Unix Makefiles\" -DCMAKE_BUILD_TYPE=Release && make -j\n",
        "\n",
        "!cd flatbuffers/python && python3 setup.py install"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'flatbuffers'...\n",
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 18346 (delta 2), reused 2 (delta 2), pack-reused 18342\u001b[K\n",
            "Receiving objects: 100% (18346/18346), 11.03 MiB | 7.84 MiB/s, done.\n",
            "Resolving deltas: 100% (12745/12745), done.\n",
            "-- The C compiler identification is GNU 7.5.0\n",
            "-- The CXX compiler identification is GNU 7.5.0\n",
            "-- Check for working C compiler: /usr/bin/cc\n",
            "-- Check for working C compiler: /usr/bin/cc -- works\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++\n",
            "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Looking for strtof_l\n",
            "-- Looking for strtof_l - found\n",
            "-- Looking for strtoull_l\n",
            "-- Looking for strtoull_l - found\n",
            "-- `tests/monster_test.fbs`: add generation of C++ code with '--no-includes;--gen-compare'\n",
            "-- `tests/monster_test.fbs`: add generation of binary (.bfbs) schema\n",
            "-- `tests/namespace_test/namespace_test1.fbs`: add generation of C++ code with '--no-includes;--gen-compare'\n",
            "-- `tests/namespace_test/namespace_test2.fbs`: add generation of C++ code with '--no-includes;--gen-compare'\n",
            "-- `tests/union_vector/union_vector.fbs`: add generation of C++ code with '--no-includes;--gen-compare'\n",
            "-- `tests/native_type_test.fbs`: add generation of C++ code with ''\n",
            "-- `tests/arrays_test.fbs`: add generation of C++ code with '--scoped-enums;--gen-compare'\n",
            "-- `tests/arrays_test.fbs`: add generation of binary (.bfbs) schema\n",
            "-- `tests/monster_test.fbs`: add generation of C++ embedded binary schema code with '--no-includes;--gen-compare'\n",
            "-- `tests/monster_extra.fbs`: add generation of C++ code with '--no-includes;--gen-compare'\n",
            "-- `samples/monster.fbs`: add generation of C++ code with '--no-includes;--gen-compare'\n",
            "-- `samples/monster.fbs`: add generation of binary (.bfbs) schema\n",
            "Proceeding with version: 1.12.0.130\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/flatbuffers\n",
            "\u001b[35m\u001b[1mScanning dependencies of target flathash\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target flatbuffers\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target flatc\u001b[0m\n",
            "[  1%] \u001b[32mBuilding CXX object CMakeFiles/flathash.dir/src/flathash.cpp.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object CMakeFiles/flatbuffers.dir/src/idl_parser.cpp.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object CMakeFiles/flatbuffers.dir/src/idl_gen_text.cpp.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding CXX object CMakeFiles/flatbuffers.dir/src/reflection.cpp.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object CMakeFiles/flatbuffers.dir/src/util.cpp.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_dart.cpp.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/reflection.cpp.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_text.cpp.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_go.cpp.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_cpp.cpp.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/util.cpp.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_csharp.cpp.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_parser.cpp.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_kotlin.cpp.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_java.cpp.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_js_ts.cpp.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_php.cpp.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_lobster.cpp.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_python.cpp.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_lua.cpp.o\u001b[0m\n",
            "[ 24%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_fbs.cpp.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_grpc.cpp.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_rust.cpp.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_json_schema.cpp.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_swift.cpp.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/flatc.cpp.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/code_generators.cpp.o\u001b[0m\n",
            "[ 32%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/flatc_main.cpp.o\u001b[0m\n",
            "[ 34%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/grpc/src/compiler/cpp_generator.cc.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/grpc/src/compiler/go_generator.cc.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/grpc/src/compiler/python_generator.cc.o\u001b[0m\n",
            "[ 37%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/grpc/src/compiler/java_generator.cc.o\u001b[0m\n",
            "[ 38%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/grpc/src/compiler/swift_generator.cc.o\u001b[0m\n",
            "[ 40%] \u001b[32m\u001b[1mLinking CXX executable flathash\u001b[0m\n",
            "[ 40%] Built target flathash\n",
            "[ 41%] \u001b[32m\u001b[1mLinking CXX static library libflatbuffers.a\u001b[0m\n",
            "[ 41%] Built target flatbuffers\n",
            "[ 42%] \u001b[32m\u001b[1mLinking CXX executable flatc\u001b[0m\n",
            "[ 42%] Built target flatc\n",
            "\u001b[35m\u001b[1mScanning dependencies of target generated_code\u001b[0m\n",
            "[ 43%] \u001b[34m\u001b[1mRun generation: 'samples/monster.bfbs'\u001b[0m\n",
            "[ 45%] \u001b[34m\u001b[1mRun generation: 'tests/monster_test.bfbs'\u001b[0m\n",
            "[ 47%] \u001b[34m\u001b[1mRun generation: 'tests/monster_test_generated.h'\u001b[0m\n",
            "[ 44%] \u001b[34m\u001b[1mRun generation: 'tests/union_vector/union_vector_generated.h'\u001b[0m\n",
            "[ 48%] \u001b[34m\u001b[1mRun generation: 'tests/monster_test_bfbs_generated.h'\u001b[0m\n",
            "[ 49%] \u001b[34m\u001b[1mRun generation: 'samples/monster_generated.h'\u001b[0m\n",
            "[ 50%] \u001b[34m\u001b[1mRun generation: 'tests/native_type_test_generated.h'\u001b[0m\n",
            "[ 51%] \u001b[34m\u001b[1mRun generation: 'tests/namespace_test/namespace_test2_generated.h'\u001b[0m\n",
            "[ 52%] \u001b[34m\u001b[1mRun generation: 'tests/namespace_test/namespace_test1_generated.h'\u001b[0m\n",
            "[ 54%] \u001b[34m\u001b[1mRun generation: 'tests/arrays_test.bfbs'\u001b[0m\n",
            "[ 55%] \u001b[34m\u001b[1mRun generation: 'tests/monster_extra_generated.h'\u001b[0m\n",
            "[ 56%] \u001b[34m\u001b[1mRun generation: 'tests/arrays_test_generated.h'\u001b[0m\n",
            "[ 57%] \u001b[34m\u001b[1mAll generated files were updated.\u001b[0m\n",
            "[ 57%] Built target generated_code\n",
            "\u001b[35m\u001b[1mScanning dependencies of target flatsampletext\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target flatsamplebinary\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target flatsamplebfbs\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target flattests\u001b[0m\n",
            "[ 58%] \u001b[32mBuilding CXX object CMakeFiles/flatsamplebinary.dir/samples/sample_binary.cpp.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object CMakeFiles/flatsampletext.dir/src/reflection.cpp.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object CMakeFiles/flatsampletext.dir/src/idl_parser.cpp.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CXX object CMakeFiles/flatsampletext.dir/src/idl_gen_text.cpp.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CXX object CMakeFiles/flatsampletext.dir/samples/sample_text.cpp.o\u001b[0m\n",
            "[ 64%] \u001b[32mBuilding CXX object CMakeFiles/flatsampletext.dir/src/util.cpp.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object CMakeFiles/flatsamplebfbs.dir/src/util.cpp.o\u001b[0m\n",
            "[ 67%] \u001b[32mBuilding CXX object CMakeFiles/flatsamplebfbs.dir/src/idl_parser.cpp.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CXX object CMakeFiles/flatsamplebfbs.dir/src/idl_gen_text.cpp.o\u001b[0m\n",
            "[ 69%] \u001b[32mBuilding CXX object CMakeFiles/flatsamplebfbs.dir/src/reflection.cpp.o\u001b[0m\n",
            "[ 70%] \u001b[32mBuilding CXX object CMakeFiles/flatsamplebfbs.dir/samples/sample_bfbs.cpp.o\u001b[0m\n",
            "[ 71%] \u001b[32mBuilding CXX object CMakeFiles/flattests.dir/src/idl_parser.cpp.o\u001b[0m\n",
            "[ 72%] \u001b[32mBuilding CXX object CMakeFiles/flattests.dir/src/reflection.cpp.o\u001b[0m\n",
            "[ 75%] \u001b[32mBuilding CXX object CMakeFiles/flattests.dir/src/idl_gen_fbs.cpp.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object CMakeFiles/flattests.dir/src/idl_gen_text.cpp.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object CMakeFiles/flattests.dir/src/util.cpp.o\u001b[0m\n",
            "[ 78%] \u001b[32mBuilding CXX object CMakeFiles/flattests.dir/tests/test_assert.cpp.o\u001b[0m\n",
            "[ 80%] \u001b[32mBuilding CXX object CMakeFiles/flattests.dir/tests/test.cpp.o\u001b[0m\n",
            "[ 81%] \u001b[32mBuilding CXX object CMakeFiles/flattests.dir/tests/native_type_test_impl.cpp.o\u001b[0m\n",
            "[ 81%] \u001b[32mBuilding CXX object CMakeFiles/flattests.dir/src/code_generators.cpp.o\u001b[0m\n",
            "[ 82%] \u001b[32mBuilding CXX object CMakeFiles/flattests.dir/tests/test_builder.cpp.o\u001b[0m\n",
            "[ 83%] \u001b[32m\u001b[1mLinking CXX executable flatsamplebinary\u001b[0m\n",
            "[ 84%] Built target flatsamplebinary\n",
            "[ 85%] \u001b[32m\u001b[1mLinking CXX executable flatsampletext\u001b[0m\n",
            "[ 87%] \u001b[32m\u001b[1mLinking CXX executable flatsamplebfbs\u001b[0m\n",
            "[ 88%] Built target flatsampletext\n",
            "[ 89%] Built target flatsamplebfbs\n",
            "[ 90%] \u001b[32m\u001b[1mLinking CXX executable flattests\u001b[0m\n",
            "[100%] Built target flattests\n",
            "VERSION environment variable not set, using datetime instead: 20200915142238\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating flatbuffers.egg-info\n",
            "writing flatbuffers.egg-info/PKG-INFO\n",
            "writing dependency_links to flatbuffers.egg-info/dependency_links.txt\n",
            "writing top-level names to flatbuffers.egg-info/top_level.txt\n",
            "writing manifest file 'flatbuffers.egg-info/SOURCES.txt'\n",
            "writing manifest file 'flatbuffers.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/flatbuffers\n",
            "copying flatbuffers/number_types.py -> build/lib/flatbuffers\n",
            "copying flatbuffers/encode.py -> build/lib/flatbuffers\n",
            "copying flatbuffers/_version.py -> build/lib/flatbuffers\n",
            "copying flatbuffers/util.py -> build/lib/flatbuffers\n",
            "copying flatbuffers/packer.py -> build/lib/flatbuffers\n",
            "copying flatbuffers/compat.py -> build/lib/flatbuffers\n",
            "copying flatbuffers/flexbuffers.py -> build/lib/flatbuffers\n",
            "copying flatbuffers/builder.py -> build/lib/flatbuffers\n",
            "copying flatbuffers/__init__.py -> build/lib/flatbuffers\n",
            "copying flatbuffers/table.py -> build/lib/flatbuffers\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/flatbuffers\n",
            "copying build/lib/flatbuffers/number_types.py -> build/bdist.linux-x86_64/egg/flatbuffers\n",
            "copying build/lib/flatbuffers/encode.py -> build/bdist.linux-x86_64/egg/flatbuffers\n",
            "copying build/lib/flatbuffers/_version.py -> build/bdist.linux-x86_64/egg/flatbuffers\n",
            "copying build/lib/flatbuffers/util.py -> build/bdist.linux-x86_64/egg/flatbuffers\n",
            "copying build/lib/flatbuffers/packer.py -> build/bdist.linux-x86_64/egg/flatbuffers\n",
            "copying build/lib/flatbuffers/compat.py -> build/bdist.linux-x86_64/egg/flatbuffers\n",
            "copying build/lib/flatbuffers/flexbuffers.py -> build/bdist.linux-x86_64/egg/flatbuffers\n",
            "copying build/lib/flatbuffers/builder.py -> build/bdist.linux-x86_64/egg/flatbuffers\n",
            "copying build/lib/flatbuffers/__init__.py -> build/bdist.linux-x86_64/egg/flatbuffers\n",
            "copying build/lib/flatbuffers/table.py -> build/bdist.linux-x86_64/egg/flatbuffers\n",
            "byte-compiling build/bdist.linux-x86_64/egg/flatbuffers/number_types.py to number_types.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/flatbuffers/encode.py to encode.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/flatbuffers/_version.py to _version.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/flatbuffers/util.py to util.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/flatbuffers/packer.py to packer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/flatbuffers/compat.py to compat.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/flatbuffers/flexbuffers.py to flexbuffers.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/flatbuffers/builder.py to builder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/flatbuffers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/flatbuffers/table.py to table.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying flatbuffers.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying flatbuffers.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying flatbuffers.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying flatbuffers.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/flatbuffers-20200915142238-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing flatbuffers-20200915142238-py3.6.egg\n",
            "Copying flatbuffers-20200915142238-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding flatbuffers 20200915142238 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/flatbuffers-20200915142238-py3.6.egg\n",
            "Processing dependencies for flatbuffers==20200915142238\n",
            "Finished processing dependencies for flatbuffers==20200915142238\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Es_dklpXsPim",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "17db4f75-701c-481a-9c46-e0a2785ec945"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/tensorflow/tensorflow/master/tensorflow/lite/schema/schema.fbs"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-15 14:22:38--  https://raw.githubusercontent.com/tensorflow/tensorflow/master/tensorflow/lite/schema/schema.fbs\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26964 (26K) [text/plain]\n",
            "Saving to: ‘schema.fbs’\n",
            "\n",
            "schema.fbs          100%[===================>]  26.33K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2020-09-15 14:22:39 (2.09 MB/s) - ‘schema.fbs’ saved [26964/26964]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olibACILtoug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!alias python=python3\n",
        "!./flatbuffers/flatc --python ./schema.fbs"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7hd2YOiwDqL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f0166288-915c-4b9a-ac0b-1bb7c1df1a05"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/google/mediapipe/master/mediapipe/models/palm_detection.tflite"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-15 14:22:39--  https://raw.githubusercontent.com/google/mediapipe/master/mediapipe/models/palm_detection.tflite\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7090152 (6.8M) [application/octet-stream]\n",
            "Saving to: ‘palm_detection.tflite’\n",
            "\n",
            "palm_detection.tfli 100%[===================>]   6.76M  21.4MB/s    in 0.3s    \n",
            "\n",
            "2020-09-15 14:22:41 (21.4 MB/s) - ‘palm_detection.tflite’ saved [7090152/7090152]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYm0vHMAsneg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "from tflite import Model"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOH6CkcQtkVa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2521f0cd-2bfa-4911-f23c-683425296d94"
      },
      "source": [
        "data = open(\"./palm_detection.tflite\", \"rb\").read()\n",
        "model = Model.Model.GetRootAsModel(data, 0)\n",
        "subgraph = model.Subgraphs(0)\n",
        "subgraph.Name()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'handdetector_hourglass_short_2019_03_25_v0.tflite.no_meta'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1Redtc7wSPh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "39815be6-683c-434f-cadf-4389e123d5cd"
      },
      "source": [
        "def get_shape(tensor):\n",
        "    return [tensor.Shape(i) for i in range(tensor.ShapeLength())]\n",
        "\n",
        "for i in range(0, subgraph.TensorsLength()):\n",
        "    tensor = subgraph.Tensors(i)\n",
        "    print(\"%3d %30s %d %2d %s\" % (i, tensor.Name(), tensor.Type(), tensor.Buffer(), \n",
        "                                  get_shape(tensor)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0                       b'input' 0  0 [1, 256, 256, 3]\n",
            "  1               b'conv2d/Kernel' 0  1 [32, 3, 3, 3]\n",
            "  2                 b'conv2d/Bias' 0  2 [32]\n",
            "  3                      b'conv2d' 0  0 [1, 128, 128, 32]\n",
            "  4                  b'activation' 0  0 [1, 128, 128, 32]\n",
            "  5     b'depthwise_conv2d/Kernel' 0  3 [1, 3, 3, 32]\n",
            "  6       b'depthwise_conv2d/Bias' 0  4 [32]\n",
            "  7            b'depthwise_conv2d' 0  0 [1, 128, 128, 32]\n",
            "  8             b'conv2d_1/Kernel' 0  5 [32, 1, 1, 32]\n",
            "  9               b'conv2d_1/Bias' 0  6 [32]\n",
            " 10                    b'conv2d_1' 0  0 [1, 128, 128, 32]\n",
            " 11                         b'add' 0  0 [1, 128, 128, 32]\n",
            " 12                b'activation_1' 0  0 [1, 128, 128, 32]\n",
            " 13   b'depthwise_conv2d_1/Kernel' 0  7 [1, 3, 3, 32]\n",
            " 14     b'depthwise_conv2d_1/Bias' 0  8 [32]\n",
            " 15          b'depthwise_conv2d_1' 0  0 [1, 128, 128, 32]\n",
            " 16             b'conv2d_2/Kernel' 0  9 [32, 1, 1, 32]\n",
            " 17               b'conv2d_2/Bias' 0 10 [32]\n",
            " 18                    b'conv2d_2' 0  0 [1, 128, 128, 32]\n",
            " 19                       b'add_1' 0  0 [1, 128, 128, 32]\n",
            " 20                b'activation_2' 0  0 [1, 128, 128, 32]\n",
            " 21   b'depthwise_conv2d_2/Kernel' 0 11 [1, 3, 3, 32]\n",
            " 22     b'depthwise_conv2d_2/Bias' 0 12 [32]\n",
            " 23          b'depthwise_conv2d_2' 0  0 [1, 128, 128, 32]\n",
            " 24             b'conv2d_3/Kernel' 0 13 [32, 1, 1, 32]\n",
            " 25               b'conv2d_3/Bias' 0 14 [32]\n",
            " 26                    b'conv2d_3' 0  0 [1, 128, 128, 32]\n",
            " 27                       b'add_2' 0  0 [1, 128, 128, 32]\n",
            " 28                b'activation_3' 0  0 [1, 128, 128, 32]\n",
            " 29   b'depthwise_conv2d_3/Kernel' 0 15 [1, 3, 3, 32]\n",
            " 30     b'depthwise_conv2d_3/Bias' 0 16 [32]\n",
            " 31          b'depthwise_conv2d_3' 0  0 [1, 128, 128, 32]\n",
            " 32             b'conv2d_4/Kernel' 0 17 [32, 1, 1, 32]\n",
            " 33               b'conv2d_4/Bias' 0 18 [32]\n",
            " 34                    b'conv2d_4' 0  0 [1, 128, 128, 32]\n",
            " 35                       b'add_3' 0  0 [1, 128, 128, 32]\n",
            " 36                b'activation_4' 0  0 [1, 128, 128, 32]\n",
            " 37   b'depthwise_conv2d_4/Kernel' 0 19 [1, 3, 3, 32]\n",
            " 38     b'depthwise_conv2d_4/Bias' 0 20 [32]\n",
            " 39          b'depthwise_conv2d_4' 0  0 [1, 128, 128, 32]\n",
            " 40             b'conv2d_5/Kernel' 0 21 [32, 1, 1, 32]\n",
            " 41               b'conv2d_5/Bias' 0 22 [32]\n",
            " 42                    b'conv2d_5' 0  0 [1, 128, 128, 32]\n",
            " 43                       b'add_4' 0  0 [1, 128, 128, 32]\n",
            " 44                b'activation_5' 0  0 [1, 128, 128, 32]\n",
            " 45   b'depthwise_conv2d_5/Kernel' 0 23 [1, 3, 3, 32]\n",
            " 46     b'depthwise_conv2d_5/Bias' 0 24 [32]\n",
            " 47          b'depthwise_conv2d_5' 0  0 [1, 128, 128, 32]\n",
            " 48             b'conv2d_6/Kernel' 0 25 [32, 1, 1, 32]\n",
            " 49               b'conv2d_6/Bias' 0 26 [32]\n",
            " 50                    b'conv2d_6' 0  0 [1, 128, 128, 32]\n",
            " 51                       b'add_5' 0  0 [1, 128, 128, 32]\n",
            " 52                b'activation_6' 0  0 [1, 128, 128, 32]\n",
            " 53   b'depthwise_conv2d_6/Kernel' 0 27 [1, 3, 3, 32]\n",
            " 54     b'depthwise_conv2d_6/Bias' 0 28 [32]\n",
            " 55          b'depthwise_conv2d_6' 0  0 [1, 128, 128, 32]\n",
            " 56             b'conv2d_7/Kernel' 0 29 [32, 1, 1, 32]\n",
            " 57               b'conv2d_7/Bias' 0 30 [32]\n",
            " 58                    b'conv2d_7' 0  0 [1, 128, 128, 32]\n",
            " 59                       b'add_6' 0  0 [1, 128, 128, 32]\n",
            " 60                b'activation_7' 0  0 [1, 128, 128, 32]\n",
            " 61   b'depthwise_conv2d_7/Kernel' 0 31 [1, 3, 3, 32]\n",
            " 62     b'depthwise_conv2d_7/Bias' 0 32 [32]\n",
            " 63          b'depthwise_conv2d_7' 0  0 [1, 64, 64, 32]\n",
            " 64               b'max_pooling2d' 0  0 [1, 64, 64, 32]\n",
            " 65             b'conv2d_8/Kernel' 0 33 [64, 1, 1, 32]\n",
            " 66               b'conv2d_8/Bias' 0 34 [64]\n",
            " 67                    b'conv2d_8' 0  0 [1, 64, 64, 64]\n",
            " 68    b'channel_padding/Paddings' 2 35 [4, 2]\n",
            " 69             b'channel_padding' 0  0 [1, 64, 64, 64]\n",
            " 70                       b'add_7' 0  0 [1, 64, 64, 64]\n",
            " 71                b'activation_8' 0  0 [1, 64, 64, 64]\n",
            " 72   b'depthwise_conv2d_8/Kernel' 0 36 [1, 3, 3, 64]\n",
            " 73     b'depthwise_conv2d_8/Bias' 0 37 [64]\n",
            " 74          b'depthwise_conv2d_8' 0  0 [1, 64, 64, 64]\n",
            " 75             b'conv2d_9/Kernel' 0 38 [64, 1, 1, 64]\n",
            " 76               b'conv2d_9/Bias' 0 39 [64]\n",
            " 77                    b'conv2d_9' 0  0 [1, 64, 64, 64]\n",
            " 78                       b'add_8' 0  0 [1, 64, 64, 64]\n",
            " 79                b'activation_9' 0  0 [1, 64, 64, 64]\n",
            " 80   b'depthwise_conv2d_9/Kernel' 0 40 [1, 3, 3, 64]\n",
            " 81     b'depthwise_conv2d_9/Bias' 0 41 [64]\n",
            " 82          b'depthwise_conv2d_9' 0  0 [1, 64, 64, 64]\n",
            " 83            b'conv2d_10/Kernel' 0 42 [64, 1, 1, 64]\n",
            " 84              b'conv2d_10/Bias' 0 43 [64]\n",
            " 85                   b'conv2d_10' 0  0 [1, 64, 64, 64]\n",
            " 86                       b'add_9' 0  0 [1, 64, 64, 64]\n",
            " 87               b'activation_10' 0  0 [1, 64, 64, 64]\n",
            " 88  b'depthwise_conv2d_10/Kernel' 0 44 [1, 3, 3, 64]\n",
            " 89    b'depthwise_conv2d_10/Bias' 0 45 [64]\n",
            " 90         b'depthwise_conv2d_10' 0  0 [1, 64, 64, 64]\n",
            " 91            b'conv2d_11/Kernel' 0 46 [64, 1, 1, 64]\n",
            " 92              b'conv2d_11/Bias' 0 47 [64]\n",
            " 93                   b'conv2d_11' 0  0 [1, 64, 64, 64]\n",
            " 94                      b'add_10' 0  0 [1, 64, 64, 64]\n",
            " 95               b'activation_11' 0  0 [1, 64, 64, 64]\n",
            " 96  b'depthwise_conv2d_11/Kernel' 0 48 [1, 3, 3, 64]\n",
            " 97    b'depthwise_conv2d_11/Bias' 0 49 [64]\n",
            " 98         b'depthwise_conv2d_11' 0  0 [1, 64, 64, 64]\n",
            " 99            b'conv2d_12/Kernel' 0 50 [64, 1, 1, 64]\n",
            "100              b'conv2d_12/Bias' 0 51 [64]\n",
            "101                   b'conv2d_12' 0  0 [1, 64, 64, 64]\n",
            "102                      b'add_11' 0  0 [1, 64, 64, 64]\n",
            "103               b'activation_12' 0  0 [1, 64, 64, 64]\n",
            "104  b'depthwise_conv2d_12/Kernel' 0 52 [1, 3, 3, 64]\n",
            "105    b'depthwise_conv2d_12/Bias' 0 53 [64]\n",
            "106         b'depthwise_conv2d_12' 0  0 [1, 64, 64, 64]\n",
            "107            b'conv2d_13/Kernel' 0 54 [64, 1, 1, 64]\n",
            "108              b'conv2d_13/Bias' 0 55 [64]\n",
            "109                   b'conv2d_13' 0  0 [1, 64, 64, 64]\n",
            "110                      b'add_12' 0  0 [1, 64, 64, 64]\n",
            "111               b'activation_13' 0  0 [1, 64, 64, 64]\n",
            "112  b'depthwise_conv2d_13/Kernel' 0 56 [1, 3, 3, 64]\n",
            "113    b'depthwise_conv2d_13/Bias' 0 57 [64]\n",
            "114         b'depthwise_conv2d_13' 0  0 [1, 64, 64, 64]\n",
            "115            b'conv2d_14/Kernel' 0 58 [64, 1, 1, 64]\n",
            "116              b'conv2d_14/Bias' 0 59 [64]\n",
            "117                   b'conv2d_14' 0  0 [1, 64, 64, 64]\n",
            "118                      b'add_13' 0  0 [1, 64, 64, 64]\n",
            "119               b'activation_14' 0  0 [1, 64, 64, 64]\n",
            "120  b'depthwise_conv2d_14/Kernel' 0 60 [1, 3, 3, 64]\n",
            "121    b'depthwise_conv2d_14/Bias' 0 61 [64]\n",
            "122         b'depthwise_conv2d_14' 0  0 [1, 64, 64, 64]\n",
            "123            b'conv2d_15/Kernel' 0 62 [64, 1, 1, 64]\n",
            "124              b'conv2d_15/Bias' 0 63 [64]\n",
            "125                   b'conv2d_15' 0  0 [1, 64, 64, 64]\n",
            "126                      b'add_14' 0  0 [1, 64, 64, 64]\n",
            "127               b'activation_15' 0  0 [1, 64, 64, 64]\n",
            "128  b'depthwise_conv2d_15/Kernel' 0 64 [1, 3, 3, 64]\n",
            "129    b'depthwise_conv2d_15/Bias' 0 65 [64]\n",
            "130         b'depthwise_conv2d_15' 0  0 [1, 32, 32, 64]\n",
            "131             b'max_pooling2d_1' 0  0 [1, 32, 32, 64]\n",
            "132            b'conv2d_16/Kernel' 0 66 [128, 1, 1, 64]\n",
            "133              b'conv2d_16/Bias' 0 67 [128]\n",
            "134                   b'conv2d_16' 0  0 [1, 32, 32, 128]\n",
            "135  b'channel_padding_1/Paddings' 2 68 [4, 2]\n",
            "136           b'channel_padding_1' 0  0 [1, 32, 32, 128]\n",
            "137                      b'add_15' 0  0 [1, 32, 32, 128]\n",
            "138               b'activation_16' 0  0 [1, 32, 32, 128]\n",
            "139  b'depthwise_conv2d_16/Kernel' 0 69 [1, 3, 3, 128]\n",
            "140    b'depthwise_conv2d_16/Bias' 0 70 [128]\n",
            "141         b'depthwise_conv2d_16' 0  0 [1, 32, 32, 128]\n",
            "142            b'conv2d_17/Kernel' 0 71 [128, 1, 1, 128]\n",
            "143              b'conv2d_17/Bias' 0 72 [128]\n",
            "144                   b'conv2d_17' 0  0 [1, 32, 32, 128]\n",
            "145                      b'add_16' 0  0 [1, 32, 32, 128]\n",
            "146               b'activation_17' 0  0 [1, 32, 32, 128]\n",
            "147  b'depthwise_conv2d_17/Kernel' 0 73 [1, 3, 3, 128]\n",
            "148    b'depthwise_conv2d_17/Bias' 0 74 [128]\n",
            "149         b'depthwise_conv2d_17' 0  0 [1, 32, 32, 128]\n",
            "150            b'conv2d_18/Kernel' 0 75 [128, 1, 1, 128]\n",
            "151              b'conv2d_18/Bias' 0 76 [128]\n",
            "152                   b'conv2d_18' 0  0 [1, 32, 32, 128]\n",
            "153                      b'add_17' 0  0 [1, 32, 32, 128]\n",
            "154               b'activation_18' 0  0 [1, 32, 32, 128]\n",
            "155  b'depthwise_conv2d_18/Kernel' 0 77 [1, 3, 3, 128]\n",
            "156    b'depthwise_conv2d_18/Bias' 0 78 [128]\n",
            "157         b'depthwise_conv2d_18' 0  0 [1, 32, 32, 128]\n",
            "158            b'conv2d_19/Kernel' 0 79 [128, 1, 1, 128]\n",
            "159              b'conv2d_19/Bias' 0 80 [128]\n",
            "160                   b'conv2d_19' 0  0 [1, 32, 32, 128]\n",
            "161                      b'add_18' 0  0 [1, 32, 32, 128]\n",
            "162               b'activation_19' 0  0 [1, 32, 32, 128]\n",
            "163  b'depthwise_conv2d_19/Kernel' 0 81 [1, 3, 3, 128]\n",
            "164    b'depthwise_conv2d_19/Bias' 0 82 [128]\n",
            "165         b'depthwise_conv2d_19' 0  0 [1, 32, 32, 128]\n",
            "166            b'conv2d_20/Kernel' 0 83 [128, 1, 1, 128]\n",
            "167              b'conv2d_20/Bias' 0 84 [128]\n",
            "168                   b'conv2d_20' 0  0 [1, 32, 32, 128]\n",
            "169                      b'add_19' 0  0 [1, 32, 32, 128]\n",
            "170               b'activation_20' 0  0 [1, 32, 32, 128]\n",
            "171  b'depthwise_conv2d_20/Kernel' 0 85 [1, 3, 3, 128]\n",
            "172    b'depthwise_conv2d_20/Bias' 0 86 [128]\n",
            "173         b'depthwise_conv2d_20' 0  0 [1, 32, 32, 128]\n",
            "174            b'conv2d_21/Kernel' 0 87 [128, 1, 1, 128]\n",
            "175              b'conv2d_21/Bias' 0 88 [128]\n",
            "176                   b'conv2d_21' 0  0 [1, 32, 32, 128]\n",
            "177                      b'add_20' 0  0 [1, 32, 32, 128]\n",
            "178               b'activation_21' 0  0 [1, 32, 32, 128]\n",
            "179  b'depthwise_conv2d_21/Kernel' 0 89 [1, 3, 3, 128]\n",
            "180    b'depthwise_conv2d_21/Bias' 0 90 [128]\n",
            "181         b'depthwise_conv2d_21' 0  0 [1, 32, 32, 128]\n",
            "182            b'conv2d_22/Kernel' 0 91 [128, 1, 1, 128]\n",
            "183              b'conv2d_22/Bias' 0 92 [128]\n",
            "184                   b'conv2d_22' 0  0 [1, 32, 32, 128]\n",
            "185                      b'add_21' 0  0 [1, 32, 32, 128]\n",
            "186               b'activation_22' 0  0 [1, 32, 32, 128]\n",
            "187  b'depthwise_conv2d_22/Kernel' 0 93 [1, 3, 3, 128]\n",
            "188    b'depthwise_conv2d_22/Bias' 0 94 [128]\n",
            "189         b'depthwise_conv2d_22' 0  0 [1, 32, 32, 128]\n",
            "190            b'conv2d_23/Kernel' 0 95 [128, 1, 1, 128]\n",
            "191              b'conv2d_23/Bias' 0 96 [128]\n",
            "192                   b'conv2d_23' 0  0 [1, 32, 32, 128]\n",
            "193                      b'add_22' 0  0 [1, 32, 32, 128]\n",
            "194               b'activation_23' 0  0 [1, 32, 32, 128]\n",
            "195  b'depthwise_conv2d_23/Kernel' 0 97 [1, 3, 3, 128]\n",
            "196    b'depthwise_conv2d_23/Bias' 0 98 [128]\n",
            "197         b'depthwise_conv2d_23' 0  0 [1, 16, 16, 128]\n",
            "198             b'max_pooling2d_2' 0  0 [1, 16, 16, 128]\n",
            "199            b'conv2d_24/Kernel' 0 99 [256, 1, 1, 128]\n",
            "200              b'conv2d_24/Bias' 0 100 [256]\n",
            "201                   b'conv2d_24' 0  0 [1, 16, 16, 256]\n",
            "202  b'channel_padding_2/Paddings' 2 101 [4, 2]\n",
            "203           b'channel_padding_2' 0  0 [1, 16, 16, 256]\n",
            "204                      b'add_23' 0  0 [1, 16, 16, 256]\n",
            "205               b'activation_24' 0  0 [1, 16, 16, 256]\n",
            "206  b'depthwise_conv2d_24/Kernel' 0 102 [1, 3, 3, 256]\n",
            "207    b'depthwise_conv2d_24/Bias' 0 103 [256]\n",
            "208         b'depthwise_conv2d_24' 0  0 [1, 16, 16, 256]\n",
            "209            b'conv2d_25/Kernel' 0 104 [256, 1, 1, 256]\n",
            "210              b'conv2d_25/Bias' 0 105 [256]\n",
            "211                   b'conv2d_25' 0  0 [1, 16, 16, 256]\n",
            "212                      b'add_24' 0  0 [1, 16, 16, 256]\n",
            "213               b'activation_25' 0  0 [1, 16, 16, 256]\n",
            "214  b'depthwise_conv2d_25/Kernel' 0 106 [1, 3, 3, 256]\n",
            "215    b'depthwise_conv2d_25/Bias' 0 107 [256]\n",
            "216         b'depthwise_conv2d_25' 0  0 [1, 16, 16, 256]\n",
            "217            b'conv2d_26/Kernel' 0 108 [256, 1, 1, 256]\n",
            "218              b'conv2d_26/Bias' 0 109 [256]\n",
            "219                   b'conv2d_26' 0  0 [1, 16, 16, 256]\n",
            "220                      b'add_25' 0  0 [1, 16, 16, 256]\n",
            "221               b'activation_26' 0  0 [1, 16, 16, 256]\n",
            "222  b'depthwise_conv2d_26/Kernel' 0 110 [1, 3, 3, 256]\n",
            "223    b'depthwise_conv2d_26/Bias' 0 111 [256]\n",
            "224         b'depthwise_conv2d_26' 0  0 [1, 16, 16, 256]\n",
            "225            b'conv2d_27/Kernel' 0 112 [256, 1, 1, 256]\n",
            "226              b'conv2d_27/Bias' 0 113 [256]\n",
            "227                   b'conv2d_27' 0  0 [1, 16, 16, 256]\n",
            "228                      b'add_26' 0  0 [1, 16, 16, 256]\n",
            "229               b'activation_27' 0  0 [1, 16, 16, 256]\n",
            "230  b'depthwise_conv2d_27/Kernel' 0 114 [1, 3, 3, 256]\n",
            "231    b'depthwise_conv2d_27/Bias' 0 115 [256]\n",
            "232         b'depthwise_conv2d_27' 0  0 [1, 16, 16, 256]\n",
            "233            b'conv2d_28/Kernel' 0 116 [256, 1, 1, 256]\n",
            "234              b'conv2d_28/Bias' 0 117 [256]\n",
            "235                   b'conv2d_28' 0  0 [1, 16, 16, 256]\n",
            "236                      b'add_27' 0  0 [1, 16, 16, 256]\n",
            "237               b'activation_28' 0  0 [1, 16, 16, 256]\n",
            "238  b'depthwise_conv2d_28/Kernel' 0 118 [1, 3, 3, 256]\n",
            "239    b'depthwise_conv2d_28/Bias' 0 119 [256]\n",
            "240         b'depthwise_conv2d_28' 0  0 [1, 16, 16, 256]\n",
            "241            b'conv2d_29/Kernel' 0 120 [256, 1, 1, 256]\n",
            "242              b'conv2d_29/Bias' 0 121 [256]\n",
            "243                   b'conv2d_29' 0  0 [1, 16, 16, 256]\n",
            "244                      b'add_28' 0  0 [1, 16, 16, 256]\n",
            "245               b'activation_29' 0  0 [1, 16, 16, 256]\n",
            "246  b'depthwise_conv2d_29/Kernel' 0 122 [1, 3, 3, 256]\n",
            "247    b'depthwise_conv2d_29/Bias' 0 123 [256]\n",
            "248         b'depthwise_conv2d_29' 0  0 [1, 16, 16, 256]\n",
            "249            b'conv2d_30/Kernel' 0 124 [256, 1, 1, 256]\n",
            "250              b'conv2d_30/Bias' 0 125 [256]\n",
            "251                   b'conv2d_30' 0  0 [1, 16, 16, 256]\n",
            "252                      b'add_29' 0  0 [1, 16, 16, 256]\n",
            "253               b'activation_30' 0  0 [1, 16, 16, 256]\n",
            "254  b'depthwise_conv2d_30/Kernel' 0 126 [1, 3, 3, 256]\n",
            "255    b'depthwise_conv2d_30/Bias' 0 127 [256]\n",
            "256         b'depthwise_conv2d_30' 0  0 [1, 16, 16, 256]\n",
            "257            b'conv2d_31/Kernel' 0 128 [256, 1, 1, 256]\n",
            "258              b'conv2d_31/Bias' 0 129 [256]\n",
            "259                   b'conv2d_31' 0  0 [1, 16, 16, 256]\n",
            "260                      b'add_30' 0  0 [1, 16, 16, 256]\n",
            "261               b'activation_31' 0  0 [1, 16, 16, 256]\n",
            "262  b'depthwise_conv2d_31/Kernel' 0 130 [1, 3, 3, 256]\n",
            "263    b'depthwise_conv2d_31/Bias' 0 131 [256]\n",
            "264         b'depthwise_conv2d_31' 0  0 [1, 8, 8, 256]\n",
            "265            b'conv2d_32/Kernel' 0 132 [256, 1, 1, 256]\n",
            "266              b'conv2d_32/Bias' 0 133 [256]\n",
            "267                   b'conv2d_32' 0  0 [1, 8, 8, 256]\n",
            "268             b'max_pooling2d_3' 0  0 [1, 8, 8, 256]\n",
            "269                      b'add_31' 0  0 [1, 8, 8, 256]\n",
            "270               b'activation_32' 0  0 [1, 8, 8, 256]\n",
            "271  b'depthwise_conv2d_32/Kernel' 0 134 [1, 3, 3, 256]\n",
            "272    b'depthwise_conv2d_32/Bias' 0 135 [256]\n",
            "273         b'depthwise_conv2d_32' 0  0 [1, 8, 8, 256]\n",
            "274            b'conv2d_33/Kernel' 0 136 [256, 1, 1, 256]\n",
            "275              b'conv2d_33/Bias' 0 137 [256]\n",
            "276                   b'conv2d_33' 0  0 [1, 8, 8, 256]\n",
            "277                      b'add_32' 0  0 [1, 8, 8, 256]\n",
            "278               b'activation_33' 0  0 [1, 8, 8, 256]\n",
            "279  b'depthwise_conv2d_33/Kernel' 0 138 [1, 3, 3, 256]\n",
            "280    b'depthwise_conv2d_33/Bias' 0 139 [256]\n",
            "281         b'depthwise_conv2d_33' 0  0 [1, 8, 8, 256]\n",
            "282            b'conv2d_34/Kernel' 0 140 [256, 1, 1, 256]\n",
            "283              b'conv2d_34/Bias' 0 141 [256]\n",
            "284                   b'conv2d_34' 0  0 [1, 8, 8, 256]\n",
            "285                      b'add_33' 0  0 [1, 8, 8, 256]\n",
            "286               b'activation_34' 0  0 [1, 8, 8, 256]\n",
            "287  b'depthwise_conv2d_34/Kernel' 0 142 [1, 3, 3, 256]\n",
            "288    b'depthwise_conv2d_34/Bias' 0 143 [256]\n",
            "289         b'depthwise_conv2d_34' 0  0 [1, 8, 8, 256]\n",
            "290            b'conv2d_35/Kernel' 0 144 [256, 1, 1, 256]\n",
            "291              b'conv2d_35/Bias' 0 145 [256]\n",
            "292                   b'conv2d_35' 0  0 [1, 8, 8, 256]\n",
            "293                      b'add_34' 0  0 [1, 8, 8, 256]\n",
            "294               b'activation_35' 0  0 [1, 8, 8, 256]\n",
            "295  b'depthwise_conv2d_35/Kernel' 0 146 [1, 3, 3, 256]\n",
            "296    b'depthwise_conv2d_35/Bias' 0 147 [256]\n",
            "297         b'depthwise_conv2d_35' 0  0 [1, 8, 8, 256]\n",
            "298            b'conv2d_36/Kernel' 0 148 [256, 1, 1, 256]\n",
            "299              b'conv2d_36/Bias' 0 149 [256]\n",
            "300                   b'conv2d_36' 0  0 [1, 8, 8, 256]\n",
            "301                      b'add_35' 0  0 [1, 8, 8, 256]\n",
            "302               b'activation_36' 0  0 [1, 8, 8, 256]\n",
            "303  b'depthwise_conv2d_36/Kernel' 0 150 [1, 3, 3, 256]\n",
            "304    b'depthwise_conv2d_36/Bias' 0 151 [256]\n",
            "305         b'depthwise_conv2d_36' 0  0 [1, 8, 8, 256]\n",
            "306            b'conv2d_37/Kernel' 0 152 [256, 1, 1, 256]\n",
            "307              b'conv2d_37/Bias' 0 153 [256]\n",
            "308                   b'conv2d_37' 0  0 [1, 8, 8, 256]\n",
            "309                      b'add_36' 0  0 [1, 8, 8, 256]\n",
            "310               b'activation_37' 0  0 [1, 8, 8, 256]\n",
            "311  b'depthwise_conv2d_37/Kernel' 0 154 [1, 3, 3, 256]\n",
            "312    b'depthwise_conv2d_37/Bias' 0 155 [256]\n",
            "313         b'depthwise_conv2d_37' 0  0 [1, 8, 8, 256]\n",
            "314            b'conv2d_38/Kernel' 0 156 [256, 1, 1, 256]\n",
            "315              b'conv2d_38/Bias' 0 157 [256]\n",
            "316                   b'conv2d_38' 0  0 [1, 8, 8, 256]\n",
            "317                      b'add_37' 0  0 [1, 8, 8, 256]\n",
            "318               b'activation_38' 0  0 [1, 8, 8, 256]\n",
            "319  b'depthwise_conv2d_38/Kernel' 0 158 [1, 3, 3, 256]\n",
            "320    b'depthwise_conv2d_38/Bias' 0 159 [256]\n",
            "321         b'depthwise_conv2d_38' 0  0 [1, 8, 8, 256]\n",
            "322            b'conv2d_39/Kernel' 0 160 [256, 1, 1, 256]\n",
            "323              b'conv2d_39/Bias' 0 161 [256]\n",
            "324                   b'conv2d_39' 0  0 [1, 8, 8, 256]\n",
            "325                      b'add_38' 0  0 [1, 8, 8, 256]\n",
            "326               b'activation_39' 0  0 [1, 8, 8, 256]\n",
            "327     b'conv2d_transpose/Kernel' 0 162 [256, 2, 2, 256]\n",
            "328       b'conv2d_transpose/Bias' 0 163 [256]\n",
            "329            b'conv2d_transpose' 0  0 [1, 16, 16, 256]\n",
            "330               b'activation_40' 0  0 [1, 16, 16, 256]\n",
            "331                      b'add_39' 0  0 [1, 16, 16, 256]\n",
            "332  b'depthwise_conv2d_39/Kernel' 0 164 [1, 3, 3, 256]\n",
            "333    b'depthwise_conv2d_39/Bias' 0 165 [256]\n",
            "334         b'depthwise_conv2d_39' 0  0 [1, 16, 16, 256]\n",
            "335            b'conv2d_40/Kernel' 0 166 [256, 1, 1, 256]\n",
            "336              b'conv2d_40/Bias' 0 167 [256]\n",
            "337                   b'conv2d_40' 0  0 [1, 16, 16, 256]\n",
            "338                      b'add_40' 0  0 [1, 16, 16, 256]\n",
            "339               b'activation_41' 0  0 [1, 16, 16, 256]\n",
            "340   b'conv2d_transpose_1/Kernel' 0 168 [128, 2, 2, 256]\n",
            "341     b'conv2d_transpose_1/Bias' 0 169 [128]\n",
            "342          b'conv2d_transpose_1' 0  0 [1, 32, 32, 128]\n",
            "343               b'activation_42' 0  0 [1, 32, 32, 128]\n",
            "344                      b'add_41' 0  0 [1, 32, 32, 128]\n",
            "345  b'depthwise_conv2d_40/Kernel' 0 170 [1, 3, 3, 128]\n",
            "346    b'depthwise_conv2d_40/Bias' 0 171 [128]\n",
            "347         b'depthwise_conv2d_40' 0  0 [1, 32, 32, 128]\n",
            "348            b'conv2d_41/Kernel' 0 172 [128, 1, 1, 128]\n",
            "349              b'conv2d_41/Bias' 0 173 [128]\n",
            "350                   b'conv2d_41' 0  0 [1, 32, 32, 128]\n",
            "351                      b'add_42' 0  0 [1, 32, 32, 128]\n",
            "352               b'activation_43' 0  0 [1, 32, 32, 128]\n",
            "353      b'classificator_8/Kernel' 0 174 [2, 1, 1, 128]\n",
            "354        b'classificator_8/Bias' 0 175 [2]\n",
            "355             b'classificator_8' 0  0 [1, 32, 32, 2]\n",
            "356     b'classificator_16/Kernel' 0 176 [2, 1, 1, 256]\n",
            "357       b'classificator_16/Bias' 0 177 [2]\n",
            "358            b'classificator_16' 0  0 [1, 16, 16, 2]\n",
            "359     b'classificator_32/Kernel' 0 178 [6, 1, 1, 256]\n",
            "360       b'classificator_32/Bias' 0 179 [6]\n",
            "361            b'classificator_32' 0  0 [1, 8, 8, 6]\n",
            "362          b'regressor_8/Kernel' 0 180 [36, 1, 1, 128]\n",
            "363            b'regressor_8/Bias' 0 181 [36]\n",
            "364                 b'regressor_8' 0  0 [1, 32, 32, 36]\n",
            "365         b'regressor_16/Kernel' 0 182 [36, 1, 1, 256]\n",
            "366           b'regressor_16/Bias' 0 183 [36]\n",
            "367                b'regressor_16' 0  0 [1, 16, 16, 36]\n",
            "368         b'regressor_32/Kernel' 0 184 [108, 1, 1, 256]\n",
            "369           b'regressor_32/Bias' 0 185 [108]\n",
            "370                b'regressor_32' 0  0 [1, 8, 8, 108]\n",
            "371                     b'reshape' 0  0 [1, 2048, 1]\n",
            "372                   b'reshape_2' 0  0 [1, 512, 1]\n",
            "373                   b'reshape_4' 0  0 [1, 384, 1]\n",
            "374                   b'reshape_1' 0  0 [1, 2048, 18]\n",
            "375                   b'reshape_3' 0  0 [1, 512, 18]\n",
            "376                   b'reshape_5' 0  0 [1, 384, 18]\n",
            "377              b'classificators' 0  0 [1, 2944, 1]\n",
            "378                  b'regressors' 0  0 [1, 2944, 18]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hqw8-zMwfGB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensor_dict = {(subgraph.Tensors(i).Name().decode(\"utf8\")): i \n",
        "               for i in range(subgraph.TensorsLength())}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYx_NcbIxTE7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2901f7b3-c631-4038-c062-c60868a026d6"
      },
      "source": [
        "parameters = {}\n",
        "for i in range(subgraph.TensorsLength()):\n",
        "    tensor = subgraph.Tensors(i)\n",
        "    if tensor.Buffer() > 0:\n",
        "        name = tensor.Name().decode(\"utf8\")\n",
        "        parameters[name] = tensor.Buffer()\n",
        "\n",
        "len(parameters)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "185"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiWrG6LjxUuQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8b999ca1-0e7c-4f07-86d5-6f0a80d0398b"
      },
      "source": [
        "def get_weights(tensor_name):\n",
        "    i = tensor_dict[tensor_name]\n",
        "    tensor = subgraph.Tensors(i)\n",
        "    buffer = tensor.Buffer()\n",
        "    shape = get_shape(tensor)\n",
        "    assert(tensor.Type() == 0)  # FLOAT32\n",
        "    \n",
        "    W = model.Buffers(buffer).DataAsNumpy()\n",
        "    W = W.view(dtype=np.float32)\n",
        "    W = W.reshape(shape)\n",
        "    return W\n",
        "W = get_weights(\"conv2d/Kernel\")\n",
        "b = get_weights(\"conv2d/Bias\")\n",
        "W.shape, b.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((32, 3, 3, 3), (32,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az5Xogryxbkq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from blazepalm import PalmDetector"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_thiJUxIxkfw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e16c3124-d98f-4098-d63a-04d820d3242b"
      },
      "source": [
        "net = PalmDetector()\n",
        "net"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PalmDetector(\n",
              "  (backbone1): Sequential(\n",
              "    (0): ConstantPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
              "    (1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2))\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): ResBlock(\n",
              "      (f): Sequential(\n",
              "        (0): ResModule(\n",
              "          (convs): Sequential(\n",
              "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
              "            (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (act): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): ResModule(\n",
              "          (convs): Sequential(\n",
              "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
              "            (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (act): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): ResModule(\n",
              "          (convs): Sequential(\n",
              "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
              "            (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (act): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): ResModule(\n",
              "          (convs): Sequential(\n",
              "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
              "            (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (act): ReLU(inplace=True)\n",
              "        )\n",
              "        (4): ResModule(\n",
              "          (convs): Sequential(\n",
              "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
              "            (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (act): ReLU(inplace=True)\n",
              "        )\n",
              "        (5): ResModule(\n",
              "          (convs): Sequential(\n",
              "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
              "            (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (act): ReLU(inplace=True)\n",
              "        )\n",
              "        (6): ResModule(\n",
              "          (convs): Sequential(\n",
              "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
              "            (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (act): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (4): ResModule(\n",
              "      (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (convs): Sequential(\n",
              "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), groups=32)\n",
              "        (1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (act): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): ResBlock(\n",
              "      (f): Sequential(\n",
              "        (0): ResModule(\n",
              "          (convs): Sequential(\n",
              "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
              "            (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (act): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): ResModule(\n",
              "          (convs): Sequential(\n",
              "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
              "            (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (act): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): ResModule(\n",
              "          (convs): Sequential(\n",
              "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
              "            (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (act): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): ResModule(\n",
              "          (convs): Sequential(\n",
              "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
              "            (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (act): ReLU(inplace=True)\n",
              "        )\n",
              "        (4): ResModule(\n",
              "          (convs): Sequential(\n",
              "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
              "            (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (act): ReLU(inplace=True)\n",
              "        )\n",
              "        (5): ResModule(\n",
              "          (convs): Sequential(\n",
              "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
              "            (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (act): ReLU(inplace=True)\n",
              "        )\n",
              "        (6): ResModule(\n",
              "          (convs): Sequential(\n",
              "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
              "            (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (act): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (6): ResModule(\n",
              "      (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (convs): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), groups=64)\n",
              "        (1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (act): ReLU(inplace=True)\n",
              "    )\n",
              "    (7): ResBlock(\n",
              "      (f): Sequential(\n",
              "        (0): ResModule(\n",
              "          (convs): Sequential(\n",
              "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
              "            (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (act): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): ResModule(\n",
              "          (convs): Sequential(\n",
              "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
              "            (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (act): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): ResModule(\n",
              "          (convs): Sequential(\n",
              "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
              "            (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (act): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): ResModule(\n",
              "          (convs): Sequential(\n",
              "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
              "            (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (act): ReLU(inplace=True)\n",
              "        )\n",
              "        (4): ResModule(\n",
              "          (convs): Sequential(\n",
              "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
              "            (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (act): ReLU(inplace=True)\n",
              "        )\n",
              "        (5): ResModule(\n",
              "          (convs): Sequential(\n",
              "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
              "            (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (act): ReLU(inplace=True)\n",
              "        )\n",
              "        (6): ResModule(\n",
              "          (convs): Sequential(\n",
              "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
              "            (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (act): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (backbone2): Sequential(\n",
              "    (0): ResModule(\n",
              "      (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (convs): Sequential(\n",
              "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), groups=128)\n",
              "        (1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (act): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): ResBlock(\n",
              "      (f): Sequential(\n",
              "        (0): ResModule(\n",
              "          (convs): Sequential(\n",
              "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
              "            (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (act): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): ResModule(\n",
              "          (convs): Sequential(\n",
              "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
              "            (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (act): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): ResModule(\n",
              "          (convs): Sequential(\n",
              "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
              "            (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (act): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): ResModule(\n",
              "          (convs): Sequential(\n",
              "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
              "            (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (act): ReLU(inplace=True)\n",
              "        )\n",
              "        (4): ResModule(\n",
              "          (convs): Sequential(\n",
              "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
              "            (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (act): ReLU(inplace=True)\n",
              "        )\n",
              "        (5): ResModule(\n",
              "          (convs): Sequential(\n",
              "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
              "            (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (act): ReLU(inplace=True)\n",
              "        )\n",
              "        (6): ResModule(\n",
              "          (convs): Sequential(\n",
              "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
              "            (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (act): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (backbone3): Sequential(\n",
              "    (0): ResModule(\n",
              "      (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (convs): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), groups=256)\n",
              "        (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (act): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): ResBlock(\n",
              "      (f): Sequential(\n",
              "        (0): ResModule(\n",
              "          (convs): Sequential(\n",
              "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
              "            (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (act): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): ResModule(\n",
              "          (convs): Sequential(\n",
              "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
              "            (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (act): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): ResModule(\n",
              "          (convs): Sequential(\n",
              "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
              "            (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (act): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): ResModule(\n",
              "          (convs): Sequential(\n",
              "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
              "            (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (act): ReLU(inplace=True)\n",
              "        )\n",
              "        (4): ResModule(\n",
              "          (convs): Sequential(\n",
              "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
              "            (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (act): ReLU(inplace=True)\n",
              "        )\n",
              "        (5): ResModule(\n",
              "          (convs): Sequential(\n",
              "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
              "            (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (act): ReLU(inplace=True)\n",
              "        )\n",
              "        (6): ResModule(\n",
              "          (convs): Sequential(\n",
              "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
              "            (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (act): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (upscale8to16): Sequential(\n",
              "    (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "  )\n",
              "  (scaled16add): ResModule(\n",
              "    (convs): Sequential(\n",
              "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
              "      (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (act): ReLU(inplace=True)\n",
              "  )\n",
              "  (upscale16to32): Sequential(\n",
              "    (0): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "  )\n",
              "  (scaled32add): ResModule(\n",
              "    (convs): Sequential(\n",
              "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
              "      (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (act): ReLU(inplace=True)\n",
              "  )\n",
              "  (class_32): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (class_16): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (class_8): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (reg_32): Conv2d(128, 36, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (reg_16): Conv2d(256, 36, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (reg_8): Conv2d(256, 108, kernel_size=(1, 1), stride=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhDQ6Rjixog4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "cca18c10-fcf1-433d-edc6-3e277f159704"
      },
      "source": [
        "probable_names = []\n",
        "for i in range(0, subgraph.TensorsLength()):\n",
        "    tensor = subgraph.Tensors(i)\n",
        "    if tensor.Buffer() > 0 and tensor.Type() == 0:\n",
        "        probable_names.append(tensor.Name().decode(\"utf-8\"))\n",
        "        \n",
        "probable_names[:5]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['conv2d/Kernel',\n",
              " 'conv2d/Bias',\n",
              " 'depthwise_conv2d/Kernel',\n",
              " 'depthwise_conv2d/Bias',\n",
              " 'conv2d_1/Kernel']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3qe4_m8xx33",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "convert = {}\n",
        "i = 0\n",
        "for name, params in net.state_dict().items():\n",
        "    convert[name] = probable_names[i]\n",
        "    i += 1"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwHum9b-x213",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fb7c6f99-cc85-4112-aab2-b5e9b1880cf5"
      },
      "source": [
        "new_state_dict = OrderedDict()\n",
        "\n",
        "for dst, src in convert.items():\n",
        "    W = get_weights(src)\n",
        "    print(dst, src, W.shape, net.state_dict()[dst].shape)\n",
        "\n",
        "    if W.ndim == 4:\n",
        "        if W.shape[0] == 1:\n",
        "            W = W.transpose((3, 0, 1, 2))  # depthwise conv\n",
        "        else:\n",
        "          if \"transpose\" in src:\n",
        "            W = W.transpose((3, 0, 1, 2)) # transpose\n",
        "          else:\n",
        "            W = W.transpose((0, 3, 1, 2))  # regular conv\n",
        "    \n",
        "    new_state_dict[dst] = torch.from_numpy(W)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "backbone1.1.weight conv2d/Kernel (32, 3, 3, 3) torch.Size([32, 3, 3, 3])\n",
            "backbone1.1.bias conv2d/Bias (32,) torch.Size([32])\n",
            "backbone1.3.f.0.convs.0.weight depthwise_conv2d/Kernel (1, 3, 3, 32) torch.Size([32, 1, 3, 3])\n",
            "backbone1.3.f.0.convs.0.bias depthwise_conv2d/Bias (32,) torch.Size([32])\n",
            "backbone1.3.f.0.convs.1.weight conv2d_1/Kernel (32, 1, 1, 32) torch.Size([32, 32, 1, 1])\n",
            "backbone1.3.f.0.convs.1.bias conv2d_1/Bias (32,) torch.Size([32])\n",
            "backbone1.3.f.1.convs.0.weight depthwise_conv2d_1/Kernel (1, 3, 3, 32) torch.Size([32, 1, 3, 3])\n",
            "backbone1.3.f.1.convs.0.bias depthwise_conv2d_1/Bias (32,) torch.Size([32])\n",
            "backbone1.3.f.1.convs.1.weight conv2d_2/Kernel (32, 1, 1, 32) torch.Size([32, 32, 1, 1])\n",
            "backbone1.3.f.1.convs.1.bias conv2d_2/Bias (32,) torch.Size([32])\n",
            "backbone1.3.f.2.convs.0.weight depthwise_conv2d_2/Kernel (1, 3, 3, 32) torch.Size([32, 1, 3, 3])\n",
            "backbone1.3.f.2.convs.0.bias depthwise_conv2d_2/Bias (32,) torch.Size([32])\n",
            "backbone1.3.f.2.convs.1.weight conv2d_3/Kernel (32, 1, 1, 32) torch.Size([32, 32, 1, 1])\n",
            "backbone1.3.f.2.convs.1.bias conv2d_3/Bias (32,) torch.Size([32])\n",
            "backbone1.3.f.3.convs.0.weight depthwise_conv2d_3/Kernel (1, 3, 3, 32) torch.Size([32, 1, 3, 3])\n",
            "backbone1.3.f.3.convs.0.bias depthwise_conv2d_3/Bias (32,) torch.Size([32])\n",
            "backbone1.3.f.3.convs.1.weight conv2d_4/Kernel (32, 1, 1, 32) torch.Size([32, 32, 1, 1])\n",
            "backbone1.3.f.3.convs.1.bias conv2d_4/Bias (32,) torch.Size([32])\n",
            "backbone1.3.f.4.convs.0.weight depthwise_conv2d_4/Kernel (1, 3, 3, 32) torch.Size([32, 1, 3, 3])\n",
            "backbone1.3.f.4.convs.0.bias depthwise_conv2d_4/Bias (32,) torch.Size([32])\n",
            "backbone1.3.f.4.convs.1.weight conv2d_5/Kernel (32, 1, 1, 32) torch.Size([32, 32, 1, 1])\n",
            "backbone1.3.f.4.convs.1.bias conv2d_5/Bias (32,) torch.Size([32])\n",
            "backbone1.3.f.5.convs.0.weight depthwise_conv2d_5/Kernel (1, 3, 3, 32) torch.Size([32, 1, 3, 3])\n",
            "backbone1.3.f.5.convs.0.bias depthwise_conv2d_5/Bias (32,) torch.Size([32])\n",
            "backbone1.3.f.5.convs.1.weight conv2d_6/Kernel (32, 1, 1, 32) torch.Size([32, 32, 1, 1])\n",
            "backbone1.3.f.5.convs.1.bias conv2d_6/Bias (32,) torch.Size([32])\n",
            "backbone1.3.f.6.convs.0.weight depthwise_conv2d_6/Kernel (1, 3, 3, 32) torch.Size([32, 1, 3, 3])\n",
            "backbone1.3.f.6.convs.0.bias depthwise_conv2d_6/Bias (32,) torch.Size([32])\n",
            "backbone1.3.f.6.convs.1.weight conv2d_7/Kernel (32, 1, 1, 32) torch.Size([32, 32, 1, 1])\n",
            "backbone1.3.f.6.convs.1.bias conv2d_7/Bias (32,) torch.Size([32])\n",
            "backbone1.4.convs.0.weight depthwise_conv2d_7/Kernel (1, 3, 3, 32) torch.Size([32, 1, 3, 3])\n",
            "backbone1.4.convs.0.bias depthwise_conv2d_7/Bias (32,) torch.Size([32])\n",
            "backbone1.4.convs.1.weight conv2d_8/Kernel (64, 1, 1, 32) torch.Size([64, 32, 1, 1])\n",
            "backbone1.4.convs.1.bias conv2d_8/Bias (64,) torch.Size([64])\n",
            "backbone1.5.f.0.convs.0.weight depthwise_conv2d_8/Kernel (1, 3, 3, 64) torch.Size([64, 1, 3, 3])\n",
            "backbone1.5.f.0.convs.0.bias depthwise_conv2d_8/Bias (64,) torch.Size([64])\n",
            "backbone1.5.f.0.convs.1.weight conv2d_9/Kernel (64, 1, 1, 64) torch.Size([64, 64, 1, 1])\n",
            "backbone1.5.f.0.convs.1.bias conv2d_9/Bias (64,) torch.Size([64])\n",
            "backbone1.5.f.1.convs.0.weight depthwise_conv2d_9/Kernel (1, 3, 3, 64) torch.Size([64, 1, 3, 3])\n",
            "backbone1.5.f.1.convs.0.bias depthwise_conv2d_9/Bias (64,) torch.Size([64])\n",
            "backbone1.5.f.1.convs.1.weight conv2d_10/Kernel (64, 1, 1, 64) torch.Size([64, 64, 1, 1])\n",
            "backbone1.5.f.1.convs.1.bias conv2d_10/Bias (64,) torch.Size([64])\n",
            "backbone1.5.f.2.convs.0.weight depthwise_conv2d_10/Kernel (1, 3, 3, 64) torch.Size([64, 1, 3, 3])\n",
            "backbone1.5.f.2.convs.0.bias depthwise_conv2d_10/Bias (64,) torch.Size([64])\n",
            "backbone1.5.f.2.convs.1.weight conv2d_11/Kernel (64, 1, 1, 64) torch.Size([64, 64, 1, 1])\n",
            "backbone1.5.f.2.convs.1.bias conv2d_11/Bias (64,) torch.Size([64])\n",
            "backbone1.5.f.3.convs.0.weight depthwise_conv2d_11/Kernel (1, 3, 3, 64) torch.Size([64, 1, 3, 3])\n",
            "backbone1.5.f.3.convs.0.bias depthwise_conv2d_11/Bias (64,) torch.Size([64])\n",
            "backbone1.5.f.3.convs.1.weight conv2d_12/Kernel (64, 1, 1, 64) torch.Size([64, 64, 1, 1])\n",
            "backbone1.5.f.3.convs.1.bias conv2d_12/Bias (64,) torch.Size([64])\n",
            "backbone1.5.f.4.convs.0.weight depthwise_conv2d_12/Kernel (1, 3, 3, 64) torch.Size([64, 1, 3, 3])\n",
            "backbone1.5.f.4.convs.0.bias depthwise_conv2d_12/Bias (64,) torch.Size([64])\n",
            "backbone1.5.f.4.convs.1.weight conv2d_13/Kernel (64, 1, 1, 64) torch.Size([64, 64, 1, 1])\n",
            "backbone1.5.f.4.convs.1.bias conv2d_13/Bias (64,) torch.Size([64])\n",
            "backbone1.5.f.5.convs.0.weight depthwise_conv2d_13/Kernel (1, 3, 3, 64) torch.Size([64, 1, 3, 3])\n",
            "backbone1.5.f.5.convs.0.bias depthwise_conv2d_13/Bias (64,) torch.Size([64])\n",
            "backbone1.5.f.5.convs.1.weight conv2d_14/Kernel (64, 1, 1, 64) torch.Size([64, 64, 1, 1])\n",
            "backbone1.5.f.5.convs.1.bias conv2d_14/Bias (64,) torch.Size([64])\n",
            "backbone1.5.f.6.convs.0.weight depthwise_conv2d_14/Kernel (1, 3, 3, 64) torch.Size([64, 1, 3, 3])\n",
            "backbone1.5.f.6.convs.0.bias depthwise_conv2d_14/Bias (64,) torch.Size([64])\n",
            "backbone1.5.f.6.convs.1.weight conv2d_15/Kernel (64, 1, 1, 64) torch.Size([64, 64, 1, 1])\n",
            "backbone1.5.f.6.convs.1.bias conv2d_15/Bias (64,) torch.Size([64])\n",
            "backbone1.6.convs.0.weight depthwise_conv2d_15/Kernel (1, 3, 3, 64) torch.Size([64, 1, 3, 3])\n",
            "backbone1.6.convs.0.bias depthwise_conv2d_15/Bias (64,) torch.Size([64])\n",
            "backbone1.6.convs.1.weight conv2d_16/Kernel (128, 1, 1, 64) torch.Size([128, 64, 1, 1])\n",
            "backbone1.6.convs.1.bias conv2d_16/Bias (128,) torch.Size([128])\n",
            "backbone1.7.f.0.convs.0.weight depthwise_conv2d_16/Kernel (1, 3, 3, 128) torch.Size([128, 1, 3, 3])\n",
            "backbone1.7.f.0.convs.0.bias depthwise_conv2d_16/Bias (128,) torch.Size([128])\n",
            "backbone1.7.f.0.convs.1.weight conv2d_17/Kernel (128, 1, 1, 128) torch.Size([128, 128, 1, 1])\n",
            "backbone1.7.f.0.convs.1.bias conv2d_17/Bias (128,) torch.Size([128])\n",
            "backbone1.7.f.1.convs.0.weight depthwise_conv2d_17/Kernel (1, 3, 3, 128) torch.Size([128, 1, 3, 3])\n",
            "backbone1.7.f.1.convs.0.bias depthwise_conv2d_17/Bias (128,) torch.Size([128])\n",
            "backbone1.7.f.1.convs.1.weight conv2d_18/Kernel (128, 1, 1, 128) torch.Size([128, 128, 1, 1])\n",
            "backbone1.7.f.1.convs.1.bias conv2d_18/Bias (128,) torch.Size([128])\n",
            "backbone1.7.f.2.convs.0.weight depthwise_conv2d_18/Kernel (1, 3, 3, 128) torch.Size([128, 1, 3, 3])\n",
            "backbone1.7.f.2.convs.0.bias depthwise_conv2d_18/Bias (128,) torch.Size([128])\n",
            "backbone1.7.f.2.convs.1.weight conv2d_19/Kernel (128, 1, 1, 128) torch.Size([128, 128, 1, 1])\n",
            "backbone1.7.f.2.convs.1.bias conv2d_19/Bias (128,) torch.Size([128])\n",
            "backbone1.7.f.3.convs.0.weight depthwise_conv2d_19/Kernel (1, 3, 3, 128) torch.Size([128, 1, 3, 3])\n",
            "backbone1.7.f.3.convs.0.bias depthwise_conv2d_19/Bias (128,) torch.Size([128])\n",
            "backbone1.7.f.3.convs.1.weight conv2d_20/Kernel (128, 1, 1, 128) torch.Size([128, 128, 1, 1])\n",
            "backbone1.7.f.3.convs.1.bias conv2d_20/Bias (128,) torch.Size([128])\n",
            "backbone1.7.f.4.convs.0.weight depthwise_conv2d_20/Kernel (1, 3, 3, 128) torch.Size([128, 1, 3, 3])\n",
            "backbone1.7.f.4.convs.0.bias depthwise_conv2d_20/Bias (128,) torch.Size([128])\n",
            "backbone1.7.f.4.convs.1.weight conv2d_21/Kernel (128, 1, 1, 128) torch.Size([128, 128, 1, 1])\n",
            "backbone1.7.f.4.convs.1.bias conv2d_21/Bias (128,) torch.Size([128])\n",
            "backbone1.7.f.5.convs.0.weight depthwise_conv2d_21/Kernel (1, 3, 3, 128) torch.Size([128, 1, 3, 3])\n",
            "backbone1.7.f.5.convs.0.bias depthwise_conv2d_21/Bias (128,) torch.Size([128])\n",
            "backbone1.7.f.5.convs.1.weight conv2d_22/Kernel (128, 1, 1, 128) torch.Size([128, 128, 1, 1])\n",
            "backbone1.7.f.5.convs.1.bias conv2d_22/Bias (128,) torch.Size([128])\n",
            "backbone1.7.f.6.convs.0.weight depthwise_conv2d_22/Kernel (1, 3, 3, 128) torch.Size([128, 1, 3, 3])\n",
            "backbone1.7.f.6.convs.0.bias depthwise_conv2d_22/Bias (128,) torch.Size([128])\n",
            "backbone1.7.f.6.convs.1.weight conv2d_23/Kernel (128, 1, 1, 128) torch.Size([128, 128, 1, 1])\n",
            "backbone1.7.f.6.convs.1.bias conv2d_23/Bias (128,) torch.Size([128])\n",
            "backbone2.0.convs.0.weight depthwise_conv2d_23/Kernel (1, 3, 3, 128) torch.Size([128, 1, 3, 3])\n",
            "backbone2.0.convs.0.bias depthwise_conv2d_23/Bias (128,) torch.Size([128])\n",
            "backbone2.0.convs.1.weight conv2d_24/Kernel (256, 1, 1, 128) torch.Size([256, 128, 1, 1])\n",
            "backbone2.0.convs.1.bias conv2d_24/Bias (256,) torch.Size([256])\n",
            "backbone2.1.f.0.convs.0.weight depthwise_conv2d_24/Kernel (1, 3, 3, 256) torch.Size([256, 1, 3, 3])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "backbone2.1.f.0.convs.0.bias depthwise_conv2d_24/Bias (256,) torch.Size([256])\n",
            "backbone2.1.f.0.convs.1.weight conv2d_25/Kernel (256, 1, 1, 256) torch.Size([256, 256, 1, 1])\n",
            "backbone2.1.f.0.convs.1.bias conv2d_25/Bias (256,) torch.Size([256])\n",
            "backbone2.1.f.1.convs.0.weight depthwise_conv2d_25/Kernel (1, 3, 3, 256) torch.Size([256, 1, 3, 3])\n",
            "backbone2.1.f.1.convs.0.bias depthwise_conv2d_25/Bias (256,) torch.Size([256])\n",
            "backbone2.1.f.1.convs.1.weight conv2d_26/Kernel (256, 1, 1, 256) torch.Size([256, 256, 1, 1])\n",
            "backbone2.1.f.1.convs.1.bias conv2d_26/Bias (256,) torch.Size([256])\n",
            "backbone2.1.f.2.convs.0.weight depthwise_conv2d_26/Kernel (1, 3, 3, 256) torch.Size([256, 1, 3, 3])\n",
            "backbone2.1.f.2.convs.0.bias depthwise_conv2d_26/Bias (256,) torch.Size([256])\n",
            "backbone2.1.f.2.convs.1.weight conv2d_27/Kernel (256, 1, 1, 256) torch.Size([256, 256, 1, 1])\n",
            "backbone2.1.f.2.convs.1.bias conv2d_27/Bias (256,) torch.Size([256])\n",
            "backbone2.1.f.3.convs.0.weight depthwise_conv2d_27/Kernel (1, 3, 3, 256) torch.Size([256, 1, 3, 3])\n",
            "backbone2.1.f.3.convs.0.bias depthwise_conv2d_27/Bias (256,) torch.Size([256])\n",
            "backbone2.1.f.3.convs.1.weight conv2d_28/Kernel (256, 1, 1, 256) torch.Size([256, 256, 1, 1])\n",
            "backbone2.1.f.3.convs.1.bias conv2d_28/Bias (256,) torch.Size([256])\n",
            "backbone2.1.f.4.convs.0.weight depthwise_conv2d_28/Kernel (1, 3, 3, 256) torch.Size([256, 1, 3, 3])\n",
            "backbone2.1.f.4.convs.0.bias depthwise_conv2d_28/Bias (256,) torch.Size([256])\n",
            "backbone2.1.f.4.convs.1.weight conv2d_29/Kernel (256, 1, 1, 256) torch.Size([256, 256, 1, 1])\n",
            "backbone2.1.f.4.convs.1.bias conv2d_29/Bias (256,) torch.Size([256])\n",
            "backbone2.1.f.5.convs.0.weight depthwise_conv2d_29/Kernel (1, 3, 3, 256) torch.Size([256, 1, 3, 3])\n",
            "backbone2.1.f.5.convs.0.bias depthwise_conv2d_29/Bias (256,) torch.Size([256])\n",
            "backbone2.1.f.5.convs.1.weight conv2d_30/Kernel (256, 1, 1, 256) torch.Size([256, 256, 1, 1])\n",
            "backbone2.1.f.5.convs.1.bias conv2d_30/Bias (256,) torch.Size([256])\n",
            "backbone2.1.f.6.convs.0.weight depthwise_conv2d_30/Kernel (1, 3, 3, 256) torch.Size([256, 1, 3, 3])\n",
            "backbone2.1.f.6.convs.0.bias depthwise_conv2d_30/Bias (256,) torch.Size([256])\n",
            "backbone2.1.f.6.convs.1.weight conv2d_31/Kernel (256, 1, 1, 256) torch.Size([256, 256, 1, 1])\n",
            "backbone2.1.f.6.convs.1.bias conv2d_31/Bias (256,) torch.Size([256])\n",
            "backbone3.0.convs.0.weight depthwise_conv2d_31/Kernel (1, 3, 3, 256) torch.Size([256, 1, 3, 3])\n",
            "backbone3.0.convs.0.bias depthwise_conv2d_31/Bias (256,) torch.Size([256])\n",
            "backbone3.0.convs.1.weight conv2d_32/Kernel (256, 1, 1, 256) torch.Size([256, 256, 1, 1])\n",
            "backbone3.0.convs.1.bias conv2d_32/Bias (256,) torch.Size([256])\n",
            "backbone3.1.f.0.convs.0.weight depthwise_conv2d_32/Kernel (1, 3, 3, 256) torch.Size([256, 1, 3, 3])\n",
            "backbone3.1.f.0.convs.0.bias depthwise_conv2d_32/Bias (256,) torch.Size([256])\n",
            "backbone3.1.f.0.convs.1.weight conv2d_33/Kernel (256, 1, 1, 256) torch.Size([256, 256, 1, 1])\n",
            "backbone3.1.f.0.convs.1.bias conv2d_33/Bias (256,) torch.Size([256])\n",
            "backbone3.1.f.1.convs.0.weight depthwise_conv2d_33/Kernel (1, 3, 3, 256) torch.Size([256, 1, 3, 3])\n",
            "backbone3.1.f.1.convs.0.bias depthwise_conv2d_33/Bias (256,) torch.Size([256])\n",
            "backbone3.1.f.1.convs.1.weight conv2d_34/Kernel (256, 1, 1, 256) torch.Size([256, 256, 1, 1])\n",
            "backbone3.1.f.1.convs.1.bias conv2d_34/Bias (256,) torch.Size([256])\n",
            "backbone3.1.f.2.convs.0.weight depthwise_conv2d_34/Kernel (1, 3, 3, 256) torch.Size([256, 1, 3, 3])\n",
            "backbone3.1.f.2.convs.0.bias depthwise_conv2d_34/Bias (256,) torch.Size([256])\n",
            "backbone3.1.f.2.convs.1.weight conv2d_35/Kernel (256, 1, 1, 256) torch.Size([256, 256, 1, 1])\n",
            "backbone3.1.f.2.convs.1.bias conv2d_35/Bias (256,) torch.Size([256])\n",
            "backbone3.1.f.3.convs.0.weight depthwise_conv2d_35/Kernel (1, 3, 3, 256) torch.Size([256, 1, 3, 3])\n",
            "backbone3.1.f.3.convs.0.bias depthwise_conv2d_35/Bias (256,) torch.Size([256])\n",
            "backbone3.1.f.3.convs.1.weight conv2d_36/Kernel (256, 1, 1, 256) torch.Size([256, 256, 1, 1])\n",
            "backbone3.1.f.3.convs.1.bias conv2d_36/Bias (256,) torch.Size([256])\n",
            "backbone3.1.f.4.convs.0.weight depthwise_conv2d_36/Kernel (1, 3, 3, 256) torch.Size([256, 1, 3, 3])\n",
            "backbone3.1.f.4.convs.0.bias depthwise_conv2d_36/Bias (256,) torch.Size([256])\n",
            "backbone3.1.f.4.convs.1.weight conv2d_37/Kernel (256, 1, 1, 256) torch.Size([256, 256, 1, 1])\n",
            "backbone3.1.f.4.convs.1.bias conv2d_37/Bias (256,) torch.Size([256])\n",
            "backbone3.1.f.5.convs.0.weight depthwise_conv2d_37/Kernel (1, 3, 3, 256) torch.Size([256, 1, 3, 3])\n",
            "backbone3.1.f.5.convs.0.bias depthwise_conv2d_37/Bias (256,) torch.Size([256])\n",
            "backbone3.1.f.5.convs.1.weight conv2d_38/Kernel (256, 1, 1, 256) torch.Size([256, 256, 1, 1])\n",
            "backbone3.1.f.5.convs.1.bias conv2d_38/Bias (256,) torch.Size([256])\n",
            "backbone3.1.f.6.convs.0.weight depthwise_conv2d_38/Kernel (1, 3, 3, 256) torch.Size([256, 1, 3, 3])\n",
            "backbone3.1.f.6.convs.0.bias depthwise_conv2d_38/Bias (256,) torch.Size([256])\n",
            "backbone3.1.f.6.convs.1.weight conv2d_39/Kernel (256, 1, 1, 256) torch.Size([256, 256, 1, 1])\n",
            "backbone3.1.f.6.convs.1.bias conv2d_39/Bias (256,) torch.Size([256])\n",
            "upscale8to16.0.weight conv2d_transpose/Kernel (256, 2, 2, 256) torch.Size([256, 256, 2, 2])\n",
            "upscale8to16.0.bias conv2d_transpose/Bias (256,) torch.Size([256])\n",
            "scaled16add.convs.0.weight depthwise_conv2d_39/Kernel (1, 3, 3, 256) torch.Size([256, 1, 3, 3])\n",
            "scaled16add.convs.0.bias depthwise_conv2d_39/Bias (256,) torch.Size([256])\n",
            "scaled16add.convs.1.weight conv2d_40/Kernel (256, 1, 1, 256) torch.Size([256, 256, 1, 1])\n",
            "scaled16add.convs.1.bias conv2d_40/Bias (256,) torch.Size([256])\n",
            "upscale16to32.0.weight conv2d_transpose_1/Kernel (128, 2, 2, 256) torch.Size([256, 128, 2, 2])\n",
            "upscale16to32.0.bias conv2d_transpose_1/Bias (128,) torch.Size([128])\n",
            "scaled32add.convs.0.weight depthwise_conv2d_40/Kernel (1, 3, 3, 128) torch.Size([128, 1, 3, 3])\n",
            "scaled32add.convs.0.bias depthwise_conv2d_40/Bias (128,) torch.Size([128])\n",
            "scaled32add.convs.1.weight conv2d_41/Kernel (128, 1, 1, 128) torch.Size([128, 128, 1, 1])\n",
            "scaled32add.convs.1.bias conv2d_41/Bias (128,) torch.Size([128])\n",
            "class_32.weight classificator_8/Kernel (2, 1, 1, 128) torch.Size([2, 128, 1, 1])\n",
            "class_32.bias classificator_8/Bias (2,) torch.Size([2])\n",
            "class_16.weight classificator_16/Kernel (2, 1, 1, 256) torch.Size([2, 256, 1, 1])\n",
            "class_16.bias classificator_16/Bias (2,) torch.Size([2])\n",
            "class_8.weight classificator_32/Kernel (6, 1, 1, 256) torch.Size([6, 256, 1, 1])\n",
            "class_8.bias classificator_32/Bias (6,) torch.Size([6])\n",
            "reg_32.weight regressor_8/Kernel (36, 1, 1, 128) torch.Size([36, 128, 1, 1])\n",
            "reg_32.bias regressor_8/Bias (36,) torch.Size([36])\n",
            "reg_16.weight regressor_16/Kernel (36, 1, 1, 256) torch.Size([36, 256, 1, 1])\n",
            "reg_16.bias regressor_16/Bias (36,) torch.Size([36])\n",
            "reg_8.weight regressor_32/Kernel (108, 1, 1, 256) torch.Size([108, 256, 1, 1])\n",
            "reg_8.bias regressor_32/Bias (108,) torch.Size([108])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmgBAAhex5OO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa693e98-1ac1-4a53-a68e-246fe292ff10"
      },
      "source": [
        "net.load_state_dict(new_state_dict, strict=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZ8fLa60zR9Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(net.state_dict(), \"palmdetector.pth\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16sbAGJ101QN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}